{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "!rm -r /content/cardiffnlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "from sklearn.metrics import precision_score, \\\n",
    "    recall_score, confusion_matrix, classification_report, \\\n",
    "    accuracy_score, f1_score\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "def simple_oneshot_evaluator(func, X_test, y_test):\n",
    "\n",
    "  prediction = []\n",
    "\n",
    "  for item in tqdm(X_test.itertuples()):\n",
    "\n",
    "    prediction.append(func(item.text))\n",
    "\n",
    "  print(confusion_matrix(y_test,prediction),accuracy_score(y_test,prediction),precision_score(y_test,prediction),recall_score(y_test,prediction),f1_score(y_test,prediction),classification_report(y_test,prediction))\n",
    "  return classification_report(y_test,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "from transformers import PreTrainedTokenizer\n",
    "\n",
    "import nltk \n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "import numpy as np\n",
    "\n",
    "import spacy\n",
    "\n",
    "\n",
    "class EncodedDataset(Dataset):\n",
    "\n",
    "  def __init__(self, input_sents: List[str], \n",
    "                input_labels: List[int],\n",
    "                tokenizer: PreTrainedTokenizer,\n",
    "                max_sequence_length: int = None, \n",
    "                max_targets: int = 5):\n",
    "      \n",
    "    self.input_sents = input_sents\n",
    "    self.input_labels = input_labels\n",
    "    self.tokenizer = tokenizer\n",
    "    self.max_sequence_length = max_sequence_length\n",
    "    self.max_targets = max_targets\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.input_sents) \n",
    "\n",
    "  def __getitem__(self, index):\n",
    "      \n",
    "    text = self.input_sents[index]\n",
    "    label = self.input_labels[index]\n",
    "    token = self.tokenizer(text, padding='max_length', max_length= self.max_sequence_length, truncation=True)\n",
    "\n",
    "    input_ids, mask_ids = torch.tensor(token['input_ids']), torch.tensor(token['attention_mask'])\n",
    "\n",
    "    return input_ids, mask_ids, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "\n",
    "def evaluate(model, test_data, tokenizer, test_labels, max_sequence_length, learning_rate, test_batch_size, device):\n",
    "    model = model.cuda()\n",
    "    test = EncodedDataset(input_sents=test_data, \n",
    "                    input_labels=test_labels, \n",
    "                    tokenizer=tokenizer, \n",
    "                    max_sequence_length=max_sequence_length)\n",
    "    \n",
    "\n",
    "    test_dataloader = DataLoader(test, batch_size=test_batch_size)\n",
    "\n",
    "\n",
    "    total_acc_test = 0\n",
    "    total_loss_test = 0\n",
    "    predictions = []\n",
    "    y_true = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():   \n",
    "      for test_input, test_mask, test_label in test_dataloader:\n",
    "        test_input = test_input.to(device)\n",
    "        test_mask = test_mask.to(device)\n",
    "        test_label = test_label.to(device)   \n",
    "\n",
    "        output = model(input_ids=test_input,\n",
    "                      attention_mask=test_mask)\n",
    "  \n",
    "        logits = output.logits\n",
    "\n",
    "        \n",
    "        acc = (logits.argmax(dim=1) == test_label).sum().item()\n",
    "\n",
    "        predictions.extend(logits.argmax(dim=1).detach().cpu().numpy())\n",
    "\n",
    "        y_true.extend(test_label.detach().cpu().numpy())\n",
    "      return predictions,y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AutoConfig\n",
    "import torch.nn.functional as F\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "import csv\n",
    "import urllib.request\n",
    "\n",
    "hatebert_tokenizer = AutoTokenizer.from_pretrained(\"Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two\")\n",
    "hatebert_model = AutoModelForSequenceClassification.from_pretrained(\"Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two\", num_labels=2)\n",
    "\n",
    "checkpoint = torch.load(\"C:/Users/psheth5/OneDrive - Arizona State University/HateSpeech Datasets/Baselines/HateBERT/Models/ConvAbuseEMNLPfull/pytorch_model.bin\")\n",
    "hatebert_model.load_state_dict(checkpoint)\n",
    "hatebert_model.to(device)\n",
    "\n",
    "def get_hatebert_prediction(sentence):\n",
    "\n",
    "  encoded_input = hatebert_tokenizer(sentence, max_length=512, truncation=True, return_tensors='pt').to(device)\n",
    "  output = hatebert_model(**encoded_input)\n",
    "  \n",
    "  probs = F.softmax(output.logits, dim=1)\n",
    "  probs = probs.detach().cpu().numpy()[0]\n",
    "\n",
    "  return np.argmax(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from transformers import AutoModelForSequenceClassification, BertTokenizer, BertForSequenceClassification, AutoConfig\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "hatebert_tokenizer = AutoTokenizer.from_pretrained(\"Hate-speech-CNERG/bert-base-uncased-hatexplain\")\n",
    "hatebert_model = AutoModelForSequenceClassification.from_pretrained(\"Hate-speech-CNERG/bert-base-uncased-hatexplain\", num_labels=3)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return hatebert_tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "def Hate_Train(lgbt_dataset,filename):\n",
    "    hatebert_tokenizer = AutoTokenizer.from_pretrained(\"Hate-speech-CNERG/bert-base-uncased-hatexplain\")\n",
    "    hatebert_model = AutoModelForSequenceClassification.from_pretrained(\"Hate-speech-CNERG/bert-base-uncased-hatexplain\", num_labels=3)\n",
    "    tokenized_datasets = lgbt_dataset.map(tokenize_function, batched=True)\n",
    "    print(tokenized_datasets)\n",
    "\n",
    "    training_args = TrainingArguments(output_dir=\"Baselines/HateXplain/Models/\"+str(filename),\n",
    "                                    overwrite_output_dir=True,\n",
    "                                    learning_rate=2e-5,\n",
    "                                    weight_decay=0.01,\n",
    "                                    per_device_train_batch_size=batch_size)\n",
    "\n",
    "    metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "    def compute_metrics(eval_pred):\n",
    "        logits, labels = eval_pred\n",
    "        predictions = np.argmax(logits, axis=-1)\n",
    "        return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=hatebert_model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_datasets[\"train\"],\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "\n",
    "# Load your training data\n",
    "files=['C:/Users/psheth5/OneDrive - Arizona State University/HateSpeech Datasets/Dataset-01_24/HateEval/HateEval_train_HB.csv',\n",
    "'C:/Users/psheth5/OneDrive - Arizona State University/HateSpeech Datasets/Dataset-01_24/HateEval/migrants/migrants_train_HB.csv',\n",
    "'C:/Users/psheth5/OneDrive - Arizona State University/HateSpeech Datasets/Dataset-01_24/HateEval/lgbt/lgbt_train_HB.csv']\n",
    "\n",
    "test_files = ['C:/Users/psheth5/OneDrive - Arizona State University/HateSpeech Datasets/Dataset-01_24/HateEval/HateEval_test_HB.csv',\n",
    "            'C:/Users/psheth5/OneDrive - Arizona State University/HateSpeech Datasets/Dataset-01_24/HateEval/migrants/migrants-test_HB.csv',\n",
    "            'C:/Users/psheth5/OneDrive - Arizona State University/HateSpeech Datasets/Dataset-01_24/HateEval/lgbt/lgbt-test_HB.csv']\n",
    "\n",
    "dataset_names = [\"HateEval\",\"HE_migrants\",\"HE_lgbt\"]\n",
    "print(files)\n",
    "filenames = set()\n",
    "for f in range(len(files)):\n",
    "        filenames.add(dataset_names[f])\n",
    "        train = files[f]\n",
    "        test = test_files[f]\n",
    "        lgbt_data_files = {\"train\": train, \"test\":test}\n",
    "        lgbt_dataset = load_dataset(\"csv\", data_files=lgbt_data_files, sep=\",\")\n",
    "        Hate_Train(lgbt_dataset,dataset_names[f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "for f in test_files:\n",
    "    data = pd.read_csv(f)\n",
    "    data = data[['text','label']]\n",
    "    data.to_csv(f.split(\".\")[0]+\"_HB.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AutoConfig\n",
    "import torch.nn.functional as F\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "import csv\n",
    "import urllib.request\n",
    "PATH = \"C:/Users/psheth5/OneDrive - Arizona State University/HateSpeech Datasets/Baselines/HateBERT/Models\"\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Load your test files.\n",
    "test_files = ['C:/Users/psheth5/OneDrive - Arizona State University/HateSpeech Datasets/Dataset-01_24/ConvAbuseEMNLPfull_Test_Modifiers.csv',\n",
    "'C:/Users/psheth5/OneDrive - Arizona State University/HateSpeech Datasets/Dataset-01_24/FoxNews_Test_Modifiers.csv',\n",
    "'C:/Users/psheth5/OneDrive - Arizona State University/HateSpeech Datasets/Dataset-01_24/GabHateCorpusannotations_Test_Modifiers.csv',\n",
    "'C:/Users/psheth5/OneDrive - Arizona State University/HateSpeech Datasets/Dataset-01_24/ICWSM18SALMINEN_Test_Modifiers.csv',\n",
    "'C:/Users/psheth5/OneDrive - Arizona State University/HateSpeech Datasets/Dataset-01_24/implicithatev1stg1posts_Test_Modifiers.csv',\n",
    "'C:/Users/psheth5/OneDrive - Arizona State University/HateSpeech Datasets/Dataset-01_24/Reddit_Test_Modifiers.csv',\n",
    "'C:/Users/psheth5/OneDrive - Arizona State University/HateSpeech Datasets/Dataset-01_24/WikiDetox_Test_Modifiers.csv',\n",
    "'C:/Users/psheth5/OneDrive - Arizona State University/HateSpeech Datasets/Dataset-01_24/Synthetic_test.csv',\n",
    "'C:/Users/psheth5/OneDrive - Arizona State University/HateSpeech Datasets/Dataset-01_24/Twi-Red-You_test.csv']\n",
    "\n",
    "def get_hatebert_prediction(sentence):\n",
    "\n",
    "  encoded_input = hatebert_tokenizer(sentence, max_length=512, truncation=True, return_tensors='pt')\n",
    "  output = hatebert_model(**encoded_input)\n",
    "  \n",
    "  probs = F.softmax(output.logits, dim=1)\n",
    "  probs = probs.detach().cpu().numpy()[0]\n",
    "\n",
    "  return np.argmax(probs)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "files = os.listdir(PATH)\n",
    "\n",
    "for f in files:\n",
    "    hatebert_tokenizer = BertTokenizer.from_pretrained(\"Hate-speech-CNERG/bert-base-uncased-hatexplain\")\n",
    "    hatebert_model = BertForSequenceClassification.from_pretrained(\"Hate-speech-CNERG/bert-base-uncased-hatexplain\")\n",
    "    checkpoint = torch.load(PATH+\"/\"+f+\"/pytorch_model.bin\")\n",
    "    hatebert_model.load_state_dict(checkpoint)\n",
    "    s = \"\"\n",
    "    for f in range(len(test_files)):\n",
    "      data = pd.read_csv(test_files[f])\n",
    "      s+= test_files[f].split(\"/\")[-1].split(\"_\")[0]+\"\\n\"\n",
    "      s+=\"*\"*100+\"\\n\"\n",
    "      s+=simple_oneshot_evaluator(get_hatebert_prediction, data, data[\"label\"])+ \"\\n\"\n",
    "    with open(\"C:/Users/psheth5/OneDrive - Arizona State University/HateSpeech Datasets/Results/HateBert_{}.txt\".format(f.split(\"/\")[-1].split(\"_\")[0]),\"w+\") as f1:\n",
    "      f1.write(s)\n",
    "      f1.close()\n",
    " \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8a6511c335c26d02572349af57853ebfcc20500c776be641a45dee87cf591594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
